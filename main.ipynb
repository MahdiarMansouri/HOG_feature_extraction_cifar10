{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-16T10:50:26.951285200Z",
     "start_time": "2024-01-16T10:50:26.919284500Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import easydict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "\n",
    "from skimage.exposure import exposure\n",
    "from skimage.feature import hog\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PreParing Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ef01ecaf5323313"
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Data transforms\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.255]\n",
    "\n",
    "data_transform = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ])\n",
    "}\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T10:50:26.982284400Z",
     "start_time": "2024-01-16T10:50:26.936284400Z"
    }
   },
   "id": "7727b44ab60a0ebc"
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Class names are ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "DataLoaders Are Ready.\n"
     ]
    }
   ],
   "source": [
    "# Loading Datasets\n",
    "datasets = {\n",
    "    'train': torchvision.datasets.CIFAR10(root='./data', train=True, transform=data_transform['train'],\n",
    "                                          download=True),\n",
    "    'val': torchvision.datasets.CIFAR10(root='./data', train=False, transform=data_transform['val'],\n",
    "                                        download=True)\n",
    "}\n",
    "# train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=data_transform['train'],\n",
    "#                                              download=True)\n",
    "# test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=data_transform['val'], download=True)\n",
    "\n",
    "# Defining class names\n",
    "class_names = datasets['train'].classes\n",
    "print(f'Class names are {class_names}')\n",
    "\n",
    "# Creating DataLoaders\n",
    "dataloaders = {x: torch.utils.data.DataLoader(dataset=datasets[x], batch_size=32, shuffle=True, num_workers=2) for x in\n",
    "               ['train', 'val']}\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "print('DataLoaders Are Ready.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T10:50:28.113875300Z",
     "start_time": "2024-01-16T10:50:26.945285400Z"
    }
   },
   "id": "60568c325b77e1a4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# HOG Feature Extraction"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e7b021d72900b68"
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "outputs": [],
   "source": [
    "# HOG Parameters\n",
    "orientations = 8\n",
    "pixels_per_cell = (8, 8)\n",
    "cells_per_block = (1, 1)\n",
    "block_norm = 'L2-Hys'\n",
    "\n",
    "\n",
    "class HOGFeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HOGFeatureExtractor, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        hog_features_list = torch.empty(32, 3, 224, 224)\n",
    "\n",
    "        # Iterating over data in each batch and extract hog features \n",
    "        for image in x:\n",
    "            # print(type(image))\n",
    "            # Convert Image to cpu tensor and numpy for hog\n",
    "            image = image.cpu().numpy().squeeze()\n",
    "            # print('image shape:', image.shape)\n",
    "\n",
    "            # Extract HOG features from each channel \n",
    "            img_channels = []\n",
    "            for idx, channel in enumerate(image):\n",
    "                # print(channel)\n",
    "                _, hog_channel = hog(\n",
    "                    channel,\n",
    "                    orientations=orientations,\n",
    "                    pixels_per_cell=pixels_per_cell,\n",
    "                    cells_per_block=cells_per_block,\n",
    "                    block_norm=block_norm,\n",
    "                    visualize=True,\n",
    "                )\n",
    "                hog_channel = exposure.rescale_intensity(hog_channel, in_range=(0, 10))\n",
    "                # print('hog channel shape:', type(hog_channel))\n",
    "                image[idx, :, :] = torch.Tensor(hog_channel)\n",
    "                # img_channels.append(np.array(hog_channel))\n",
    "                                \n",
    "            # img_hog = np.dstack(img_channels)\n",
    "            # print('image hog shape:', img_hog.shape, end='\\n')\n",
    "            # print(image.shape)\n",
    "            # print(type(image))\n",
    "            image = torch.FloatTensor(image)\n",
    "            hog_features_list.add_(image)\n",
    "        \n",
    "        \n",
    "        hog_features_list = torch.Tensor(hog_features_list)        \n",
    "        \n",
    "        return hog_features_list.to(device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T10:50:28.124875900Z",
     "start_time": "2024-01-16T10:50:28.102875300Z"
    }
   },
   "id": "cd23da0837f7eb2a"
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "outputs": [],
   "source": [
    "# # HOG Parameters\n",
    "# orientations = 8\n",
    "# pixels_per_cell = (8, 8)\n",
    "# cells_per_block = (1, 1)\n",
    "# block_norm = 'L2-Hys'\n",
    "# \n",
    "# \n",
    "# class HOGFeatureExtractor(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(HOGFeatureExtractor, self).__init__()\n",
    "# \n",
    "#     def forward(self, x):\n",
    "#         hog_features_list = []\n",
    "#         # Iterating over data in each batch and extract hog features \n",
    "#         for image in x:\n",
    "#             # Convert Image to cpu tensor and numpy for hog\n",
    "#             image = image.cpu().numpy().squeeze()\n",
    "#             print('image shape:', image.shape)\n",
    "# \n",
    "#             # Extract HOG features from each channel \n",
    "#             img_channels = []\n",
    "#             for channel in image:\n",
    "#                 # print(channel)\n",
    "#                 _, hog_channel = hog(\n",
    "#                     channel,\n",
    "#                     orientations=orientations,\n",
    "#                     pixels_per_cell=pixels_per_cell,\n",
    "#                     cells_per_block=cells_per_block,\n",
    "#                     block_norm=block_norm,\n",
    "#                     visualize=True,\n",
    "#                 )\n",
    "#                 hog_channel = exposure.rescale_intensity(hog_channel, in_range=(0, 10))\n",
    "#                 print('hog channel shape:', hog_channel.shape)\n",
    "#                 img_channels.append(np.array(hog_channel))\n",
    "#                                 \n",
    "#             img_hog = np.dstack(img_channels)\n",
    "#             print('image hog shape:', img_hog.shape, end='\\n')\n",
    "#             hog_features_list.append(img_hog)\n",
    "# \n",
    "#         return torch.tensor(np.array(hog_features_list), dtype=torch.float32)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T10:50:28.148875500Z",
     "start_time": "2024-01-16T10:50:28.117875800Z"
    }
   },
   "id": "18cb594d33240960"
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "outputs": [],
   "source": [
    "# # HOG Parameters\n",
    "# orientations = 9\n",
    "# pixels_per_cell = (8, 8)\n",
    "# cells_per_block = (2, 2)\n",
    "# block_norm = 'L2-Hys'\n",
    "# \n",
    "# \n",
    "# class HOGFeatureExtractor(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(HOGFeatureExtractor, self).__init__()\n",
    "# \n",
    "#     def forward(self, x):\n",
    "#         hog_features_list = []\n",
    "#         # Iterating over data in each batch and extract hog features \n",
    "#         for image in x:\n",
    "#             # Convert Image to cpu tensor and numpy for hog\n",
    "#             image = image.cpu()\n",
    "#             np_image = image.numpy().squeeze()\n",
    "# \n",
    "#             # Extract HOG features from each channel \n",
    "#             img_channels = []\n",
    "#             for channel_num in range(np_image.shape[2]):\n",
    "#                 hog_channel = hog(\n",
    "#                     np_image[:, :, channel_num],\n",
    "#                     orientations=orientations,\n",
    "#                     pixels_per_cell=pixels_per_cell,\n",
    "#                     cells_per_block=cells_per_block,\n",
    "#                     block_norm=block_norm\n",
    "#                 )\n",
    "#                 hog_channel = exposure.rescale_intensity(hog_channel, in_range=(0, 10))\n",
    "#                 img_channels.append(hog_channel)\n",
    "# \n",
    "#             img_hog = np.dstack((np.array(img_channels[0]), np.array(img_channels[1]), np.array(img_channels[2])))\n",
    "#             hog_features_list.append(img_hog)\n",
    "# \n",
    "#         return torch.tensor(np.array(hog_features_list), dtype=torch.float32)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T10:50:28.152875500Z",
     "start_time": "2024-01-16T10:50:28.133874900Z"
    }
   },
   "id": "5fb63c96b12c35c3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Setup pretrained model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c9d6bdd036e1839"
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "outputs": [],
   "source": [
    "# Load pretrained model\n",
    "pretrained_model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Freeze all trainable layers\n",
    "for param in pretrained_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modifying last classification layer for our dataset\n",
    "num_features = pretrained_model.fc.in_features\n",
    "pretrained_model.fc = nn.Linear(num_features, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T10:50:28.243879500Z",
     "start_time": "2024-01-16T10:50:28.150875600Z"
    }
   },
   "id": "628d3132ed48a91a"
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "outputs": [],
   "source": [
    "# Defining loss function and optimizer \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(pretrained_model.fc.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T10:50:28.259880300Z",
     "start_time": "2024-01-16T10:50:28.244880500Z"
    }
   },
   "id": "1a5dbebafb55c0bc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train Function "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5b4b8f5d5246d2d"
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "outputs": [],
   "source": [
    "hog_features_extractor = HOGFeatureExtractor()\n",
    "\n",
    "acc_list = easydict.EasyDict({'train': [], 'val': []})\n",
    "loss_list = easydict.EasyDict({'train': [], 'val': []})\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, epoch_num=25):\n",
    "    # Copy the best model weights for loading at the End\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    # Iterating over epochs\n",
    "    for epoch in range(1, epoch_num + 1):\n",
    "        print(f'Epoch {epoch}/{epoch_num}:')\n",
    "\n",
    "        # Each epoch has two phase Train and Validation\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            # For calculating Loss and Accuracy at the end of epoch\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0.0\n",
    "\n",
    "            # Iterating over batches and data for training and validation\n",
    "            for idx, batch in enumerate(dataloaders[phase], 0):\n",
    "                print(f'Batch {idx + 1}/{len(dataloaders[phase])} processing...')\n",
    "                inputs, labels = batch\n",
    "\n",
    "                # Transfer data and labels to CUDA if is available\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Extract HOG features\n",
    "                input_hog_features = hog_features_extractor(inputs)\n",
    "                \n",
    "                print('data processing done...')\n",
    "\n",
    "                # Forward Pass\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(input_hog_features)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    _, predictions = torch.max(outputs, 1)\n",
    "                    \n",
    "                    # Back Propagation and updating weights\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * input_hog_features.size(0)\n",
    "                running_corrects += torch.sum(predictions == labels.data)\n",
    "            \n",
    "            # Calculating Accuracy and Loss per phase\n",
    "            epoch_loss = running_loss / len(datasets[phase])\n",
    "            epoch_accuracy = running_corrects.double() / len(datasets[phase])\n",
    "            \n",
    "            # Show epoch details\n",
    "            print(f'{phase.capitalize()} Accuracy: {epoch_accuracy:.4f} / Loss: {epoch_loss:.4f}')\n",
    "            \n",
    "            # Copy the model weights if its better\n",
    "            if phase == 'val' and epoch_accuracy > best_accuracy:\n",
    "                best_accuracy = epoch_accuracy\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())  \n",
    "                print('Best model weights updated!')\n",
    "                \n",
    "            # Save Loss and accuracy\n",
    "            acc_list[phase].append(epoch_accuracy)\n",
    "            loss_list[phase].append(epoch_loss)\n",
    "        print()\n",
    "        \n",
    "    print(f'Best Accuracy: {best_accuracy:.4f}')\n",
    "    \n",
    "    # Loading best model weights \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T10:50:28.276879600Z",
     "start_time": "2024-01-16T10:50:28.264880Z"
    }
   },
   "id": "91d1322ab091488d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:\n",
      "Batch 1/1563 processing...\n",
      "data processing done...\n",
      "Batch 2/1563 processing...\n",
      "data processing done...\n",
      "Batch 3/1563 processing...\n",
      "data processing done...\n",
      "Batch 4/1563 processing...\n",
      "data processing done...\n",
      "Batch 5/1563 processing...\n",
      "data processing done...\n",
      "Batch 6/1563 processing...\n",
      "data processing done...\n",
      "Batch 7/1563 processing...\n",
      "data processing done...\n",
      "Batch 8/1563 processing...\n",
      "data processing done...\n",
      "Batch 9/1563 processing...\n"
     ]
    }
   ],
   "source": [
    "model = pretrained_model.to(device)\n",
    "\n",
    "# Train model\n",
    "model = train_model(model, criterion, optimizer, 100)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-01-16T10:50:28.277879500Z"
    }
   },
   "id": "cb0e0f22f93f88a7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "3799f650fee2907f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
